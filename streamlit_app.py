import streamlit as st
import pdfplumber
import pandas as pd
import anthropic
import tempfile
import os
from datetime import datetime
import plotly.express as px
import networkx as nx
import matplotlib.pyplot as plt
import io
import re
from PIL import Image

# APIã‚­ãƒ¼ã®è¨­å®š - Streamlitã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰èª­ã¿è¾¼ã‚€
# ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã¯st.secrets["CLAUDE_API_KEY"]ã®å½¢å¼ã§ä½¿ç”¨
# ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºæ™‚ã¯ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨
CLAUDE_API_KEY = os.environ.get("CLAUDE_API_KEY") or st.secrets.get("CLAUDE_API_KEY", "YOUR_CLAUDE_API_KEY")

# ã‚¢ãƒ—ãƒªã®è¨­å®š
st.set_page_config(
    page_title="è«–æ–‡ã‚¢ãƒ¼ã‚®ãƒ¥ãƒ¡ãƒ³ãƒˆå¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
with st.sidebar:
    st.title("âš™ï¸ è¨­å®š")
    model_option = st.selectbox(
        "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
        ["claude-3-opus-20240229", "claude-3-sonnet-20240229", "claude-3-haiku-20240307"]
    )
    temperature = st.slider("æ¸©åº¦ï¼ˆå‰µé€ æ€§ï¼‰", 0.0, 1.0, 0.3, 0.1)
    max_tokens = st.slider("æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°", 500, 4000, 1024, 100)
    st.divider()
    st.markdown("### ğŸ“Š åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    extract_claims = st.checkbox("ä¸»å¼µãƒ»æ ¹æ‹ ã‚’æŠ½å‡º", value=True)
    analyze_conversation = st.checkbox("ä¼šè©±æ§‹é€ ã‚’åˆ†æ", value=True)
    visualize_network = st.checkbox("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã‚’ç”Ÿæˆ", value=True)
    st.divider()
    st.markdown("### ğŸ› ï¸ é–‹ç™ºè€…æƒ…å ±")
    st.info("ãƒãƒ¼ã‚¸ãƒ§ãƒ³: 1.0.0 (2025-03-25)")

# ãƒ¡ã‚¤ãƒ³ç”»é¢
st.title("ğŸ“š è«–æ–‡ä¼šè©±æ§‹é€ ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ»ãƒ„ãƒ¼ãƒ«")
st.markdown("""
ã“ã®ãƒ„ãƒ¼ãƒ«ã§ã¯ã€PDFè«–æ–‡ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€å„æ®µè½ã®ä¸»å¼µãƒ»æ ¹æ‹ ã‚’æŠ½å‡ºã—ã€
ã•ã‚‰ã«è¤‡æ•°ã®è«–æ–‡é–“ã®å…±é€šå‰æã‚„ä¼šè©±æ§‹é€ ã‚’Claudeã«ã‚ˆã£ã¦è§£æãƒ»è¡¨ç¤ºã—ã¾ã™ã€‚

**ä½¿ã„æ–¹:**
1. è¤‡æ•°ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
2. ã€Œåˆ†æé–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
3. çµæœã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦CSVã‚„ã‚°ãƒ©ãƒ•ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
""")

# ã‚¿ãƒ–ã®è¨­å®š
tab1, tab2, tab3 = st.tabs(["ğŸ“„ PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“ åˆ†æçµæœ", "ğŸ” ä¼šè©±æ§‹é€ "])

with tab1:
    uploaded_files = st.file_uploader("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¤‡æ•°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"], accept_multiple_files=True)
    
    if uploaded_files:
        file_info = []
        for file in uploaded_files:
            file_info.append({
                "ãƒ•ã‚¡ã‚¤ãƒ«å": file.name,
                "ã‚µã‚¤ã‚º": f"{file.size / 1024:.1f} KB"
            })
        st.table(pd.DataFrame(file_info))
        
        if st.button("ğŸ” åˆ†æé–‹å§‹", use_container_width=True):
            all_paragraphs = []
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®è¡¨ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
            for i, uploaded_file in enumerate(uploaded_files):
                status_text.text(f"PDFå‡¦ç†ä¸­: {uploaded_file.name}")
                
                try:
                    with pdfplumber.open(uploaded_file) as pdf:
                        full_text = "\n".join([page.extract_text() or "" for page in pdf.pages])
                        
                    # ãƒ‘ãƒ©ã‚°ãƒ©ãƒ•ã«åˆ†å‰²ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
                    paragraphs = []
                    for p in re.split(r'\n{2,}', full_text):
                        # çŸ­ã™ãã‚‹è¡Œã‚„å‚è€ƒæ–‡çŒ®ã®ã‚ˆã†ãªè¡Œã¯é™¤å¤–
                        p = p.strip()
                        if len(p) > 50 and not p.startswith("References") and not re.match(r'^[\d\s\.]+$', p):
                            paragraphs.append(p)
                    
                    for j, para in enumerate(paragraphs):
                        all_paragraphs.append({
                            "source": uploaded_file.name,
                            "paragraph_id": f"{uploaded_file.name}-p{j+1}",
                            "text": para,
                            "char_count": len(para)
                        })
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼ ({uploaded_file.name}): {str(e)}")
                
                # é€²æ—æ›´æ–°
                progress_bar.progress((i + 1) / len(uploaded_files) / 2)  # å…¨ä½“ã®50%ã‚’PDFå‡¦ç†ã«
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            st.session_state.all_paragraphs = all_paragraphs
            
            # Claudeã§ã®åˆ†æ
            if extract_claims and len(all_paragraphs) > 0:
                try:
                    client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)
                    
                    for i, p in enumerate(all_paragraphs):
                        status_text.text(f"æ®µè½åˆ†æä¸­ ({i+1}/{len(all_paragraphs)}): {p['paragraph_id']}")
                        
                        prompt = f"""
ã‚ãªãŸã¯ã‚¢ã‚«ãƒ‡ãƒŸãƒƒã‚¯ãƒ»ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã®å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®æ®µè½ã‹ã‚‰ã€ä¸»å¼µï¼ˆClaimï¼‰ã¨æ ¹æ‹ ï¼ˆEvidenceï¼‰ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
æ–‡ç« ã«ä¸»å¼µã‚„æ ¹æ‹ ãŒæ˜ç¢ºã«å«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯ã€Œç‰¹å®šã§ãã¾ã›ã‚“ã€ã¨è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚

æ®µè½:
"""
{p['text']}
"""

å‡ºåŠ›å½¢å¼ï¼ˆå¿…ãšã“ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼‰:
- ä¸»å¼µ: ï¼ˆä¸»å¼µã®å†…å®¹ã¾ãŸã¯ã€Œç‰¹å®šã§ãã¾ã›ã‚“ã€ï¼‰
- æ ¹æ‹ : ï¼ˆæ ¹æ‹ ã®å†…å®¹ã¾ãŸã¯ã€Œç‰¹å®šã§ãã¾ã›ã‚“ã€ï¼‰
"""
                        try:
                            response = client.messages.create(
                                model=model_option,
                                max_tokens=max_tokens,
                                temperature=temperature,
                                messages=[{"role": "user", "content": prompt}]
                            )
                            p["analysis"] = response.content[0].text.strip()
                        except Exception as e:
                            p["analysis"] = f"Error: {e}"
                        
                        # é€²æ—æ›´æ–°ï¼ˆæ®‹ã‚Šã®50%ã‚’åˆ†æã«ï¼‰
                        progress_value = 0.5 + ((i + 1) / len(all_paragraphs) / 2)
                        progress_bar.progress(min(progress_value, 1.0))
                    
                    # ä¼šè©±æ§‹é€ ã®åˆ†æ
                    if analyze_conversation:
                        status_text.text("ä¼šè©±æ§‹é€ ã‚’åˆ†æä¸­...")
                        
                        grouped_by_source = {}
                        for p in all_paragraphs:
                            grouped_by_source.setdefault(p["source"], []).append(p)
                            
                        combined_summaries = ""
                        for src, paras in grouped_by_source.items():
                            combined_summaries += f"\n--- è«–æ–‡: {src} ---\n"
                            # å„è«–æ–‡ã‹ã‚‰æœ€å¤§5æ®µè½ã‚’ä½¿ç”¨
                            for p in paras[:5]:
                                combined_summaries += f"- {p.get('analysis', 'åˆ†æãªã—')}\n"
                        
                        conversation_prompt = f"""
ä»¥ä¸‹ã¯è¤‡æ•°ã®è«–æ–‡ã«ãŠã‘ã‚‹ä¸»å¼µã¨æ ¹æ‹ ã®æŠœç²‹ã§ã™ã€‚
ã“ã‚Œã‚‰ã®æ–‡çŒ®ãŒå…±é€šã—ã¦å‰æã¨ã—ã¦ã„ã‚‹ç†è«–ãƒ»ç™ºæƒ³ãƒ»å•é¡Œè¨­å®šã«ã¤ã„ã¦è©³ã—ãåˆ†æã—ã¦ãã ã•ã„ã€‚
ã¾ãŸã€ãã‚Œã‚‰ã«å¯¾ã—ã¦æ–°ã—ã„ä¸»å¼µãŒä»‹å…¥ã™ã‚‹ä½™åœ°ãŒã‚ã‚‹ã‹ã€ã©ã®ã‚ˆã†ã«ã€Œä¼šè©±ã®æ§‹é€ ã‚’æ›´æ–°ã€ã§ãã‚‹ã‹ã‚’å…·ä½“çš„ã«ææ¡ˆã—ã¦ãã ã•ã„ã€‚

åˆ†æé …ç›®:
1. å…±é€šã®å‰æãƒ»ç†è«–åŸºç›¤
2. å¯¾ç«‹ã™ã‚‹ä¸»å¼µç‚¹
3. æœªæ¢ç´¢ã®é ˜åŸŸãƒ»ç ”ç©¶ã®éš™é–“
4. ä¼šè©±æ§‹é€ ã®æ›´æ–°å¯èƒ½æ€§

{combined_summaries}

å‡ºåŠ›ã¯ç®‡æ¡æ›¸ãã§ã¯ãªãã€å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«æ®µè½å½¢å¼ã§è©³ç´°ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
"""
                        try:
                            convo_response = client.messages.create(
                                model=model_option,
                                max_tokens=max_tokens * 2,
                                temperature=temperature,
                                messages=[{"role": "user", "content": conversation_prompt}]
                            )
                            st.session_state.conversation_analysis = convo_response.content[0].text.strip()
                        except Exception as e:
                            st.session_state.conversation_analysis = f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                
                except Exception as e:
                    st.error(f"Claude APIã‚¨ãƒ©ãƒ¼: {str(e)}")
                    if "invalid_api_key" in str(e).lower():
                        st.warning("APIã‚­ãƒ¼ãŒç„¡åŠ¹ã¾ãŸã¯æœªè¨­å®šã§ã™ã€‚Streamlitã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã§æ­£ã—ã„APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
            
            # å‡¦ç†å®Œäº†
            progress_bar.progress(1.0)
            status_text.text("âœ… åˆ†æå®Œäº†")
            
            # çµæœè¡¨ç¤ºã‚¿ãƒ–ã«åˆ‡ã‚Šæ›¿ãˆ
            st.session_state.active_tab = "åˆ†æçµæœ"
            st.experimental_rerun()

with tab2:
    if hasattr(st.session_state, "all_paragraphs") and len(st.session_state.all_paragraphs) > 0:
        result_df = pd.DataFrame(st.session_state.all_paragraphs)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        col1, col2 = st.columns(2)
        with col1:
            source_filter = st.multiselect(
                "è«–æ–‡ã§çµã‚Šè¾¼ã¿",
                options=sorted(result_df["source"].unique()),
                default=sorted(result_df["source"].unique())
            )
        with col2:
            min_length = st.slider("æœ€å°æ–‡å­—æ•°", 0, 1000, 50, 10)
            
        # ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨
        filtered_df = result_df[
            (result_df["source"].isin(source_filter)) &
            (result_df["char_count"] >= min_length)
        ]
        
        # çµæœè¡¨ç¤º
        if "analysis" in filtered_df.columns:
            st.dataframe(
                filtered_df[["paragraph_id", "source", "char_count", "analysis"]],
                use_container_width=True,
                height=400,
                column_config={
                    "paragraph_id": "æ®µè½ID",
                    "source": "è«–æ–‡",
                    "char_count": "æ–‡å­—æ•°",
                    "analysis": "ä¸»å¼µãƒ»æ ¹æ‹ åˆ†æ"
                }
            )
            
            # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
            col1, col2 = st.columns(2)
            with col1:
                csv = filtered_df.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    "ğŸ“¥ CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", 
                    csv, 
                    f"analysis_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv", 
                    "text/csv",
                    use_container_width=True
                )
            
            with col2:
                # ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–
                if "analysis" in filtered_df.columns:
                    # ä¸»å¼µã¨æ ¹æ‹ ã®æ•°ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                    claims_count = filtered_df["analysis"].str.contains("ä¸»å¼µ:").sum()
                    evidence_count = filtered_df["analysis"].str.contains("æ ¹æ‹ :").sum()
                    has_both = filtered_df["analysis"].str.contains("ä¸»å¼µ:") & filtered_df["analysis"].str.contains("æ ¹æ‹ :")
                    both_count = has_both.sum()
                    
                    chart_data = pd.DataFrame({
                        "è¦ç´ ": ["ä¸»å¼µã®ã¿", "æ ¹æ‹ ã®ã¿", "ä¸»å¼µã¨æ ¹æ‹ "],
                        "æ•°": [claims_count - both_count, evidence_count - both_count, both_count]
                    })
                    
                    fig = px.bar(chart_data, x="è¦ç´ ", y="æ•°", title="æ®µè½ã®åˆ†æçµæœ")
                    st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ä¸»å¼µãƒ»æ ¹æ‹ ã®åˆ†æãŒã¾ã è¡Œã‚ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        st.info("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")

with tab3:
    if hasattr(st.session_state, "conversation_analysis"):
        st.markdown("### ğŸ—£ è«–æ–‡é–“ã®ä¼šè©±æ§‹é€ åˆ†æ")
        st.markdown(st.session_state.conversation_analysis)
        
        if hasattr(st.session_state, "all_paragraphs") and len(st.session_state.all_paragraphs) > 0 and visualize_network:
            st.markdown("### ğŸ•¸ è«–æ–‡é–¢ä¿‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³")
            
            try:
                # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•ã®ä½œæˆ
                G = nx.Graph()
                
                # è«–æ–‡ã‚’ãƒãƒ¼ãƒ‰ã¨ã—ã¦è¿½åŠ 
                sources = [p["source"] for p in st.session_state.all_paragraphs]
                unique_sources = list(set(sources))
                
                for source in unique_sources:
                    G.add_node(source, type="paper")
                
                # ã‚‚ã—è«–æ–‡ãŒ2ã¤ä»¥ä¸Šã‚ã‚Œã°ã€é–¢é€£æ€§ã‚’ç°¡æ˜“çš„ã«ä½œæˆ
                if len(unique_sources) >= 2:
                    for i in range(len(unique_sources)):
                        for j in range(i+1, len(unique_sources)):
                            G.add_edge(unique_sources[i], unique_sources[j], weight=1)
                
                # ã‚°ãƒ©ãƒ•ã®æç”»
                plt.figure(figsize=(10, 8))
                pos = nx.spring_layout(G, seed=42)
                
                nx.draw_networkx_nodes(G, pos, 
                                    node_size=2000, 
                                    node_color='skyblue')
                
                nx.draw_networkx_edges(G, pos, width=2, alpha=0.7)
                nx.draw_networkx_labels(G, pos, font_size=12, font_family='sans-serif')
                
                plt.axis('off')
                
                # ç”»åƒã‚’ãƒãƒƒãƒ•ã‚¡ã«ä¿å­˜
                buf = io.BytesIO()
                plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')
                buf.seek(0)
                
                # ç”»åƒã‚’è¡¨ç¤º
                st.image(buf, caption='è«–æ–‡é–¢ä¿‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³', use_column_width=True)
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                btn = st.download_button(
                    label="ğŸ“¥ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=buf,
                    file_name=f"network_graph_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                    mime="image/png",
                    use_container_width=True
                )
            except Exception as e:
                st.error(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›³ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    else:
        st.info("ä¼šè©±æ§‹é€ ã®åˆ†æãŒã¾ã è¡Œã‚ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

# ã‚‚ã—ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¿ãƒ–ã®æŒ‡å®šãŒã‚ã‚Œã°ã€ãã®ã‚¿ãƒ–ã«ç§»å‹•
if hasattr(st.session_state, "active_tab"):
    if st.session_state.active_tab == "åˆ†æçµæœ":
        # æ³¨: å®Ÿéš›ã®ã‚¿ãƒ–ã®é·ç§»ã¯Streamlitã®åˆ¶ç´„ä¸Šã€ã“ã“ã§ã¯ç›´æ¥åˆ¶å¾¡ã§ãã¾ã›ã‚“
        pass
